import { readFileSync } from 'fs';
import { VideoIntelligenceServiceClient, protos } from '@google-cloud/video-intelligence';
import config from '@/lib/config';
import { VideoIntelligenceResults } from '@/types';

export interface VideoAnalysisOptions {
  enableVoiceAnalysis?: boolean;
  enableGestureRecognition?: boolean;
  enableObjectDetection?: boolean;
  enableFaceDetection?: boolean;
  enableTranscription?: boolean;
  enableSpeakerDiarization?: boolean;
  enableSentimentAnalysis?: boolean;
  enableQualityMetrics?: boolean;
  enableComprehensiveAnalysis?: boolean;
}

export class VideoAnalyzer {
  private readonly client: VideoIntelligenceServiceClient;
  private readonly features: protos.google.cloud.videointelligence.v1.Feature[];

  constructor() {
    this.client = new VideoIntelligenceServiceClient({
      projectId: config.googleCloud.projectId,
      keyFilename: config.googleCloud.keyFile,
    });

    this.features = [
      protos.google.cloud.videointelligence.v1.Feature.OBJECT_TRACKING,
      protos.google.cloud.videointelligence.v1.Feature.FACE_DETECTION,
      protos.google.cloud.videointelligence.v1.Feature.PERSON_DETECTION,
      protos.google.cloud.videointelligence.v1.Feature.SHOT_CHANGE_DETECTION,
      protos.google.cloud.videointelligence.v1.Feature.SPEECH_TRANSCRIPTION,
      protos.google.cloud.videointelligence.v1.Feature.TEXT_DETECTION,
    ];
  }

  /**
   * ÎπÑÎîîÏò§ Î∂ÑÏÑù Î∞è Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Ï∂îÏ∂ú
   */
  async analyzeVideo(
    videoInput: string | Buffer, 
    options: VideoAnalysisOptions = {}
  ): Promise<VideoIntelligenceResults> {
    try {
      let request: any;

      // ÏûÖÎ†• ÌÉÄÏûÖÏóê Îî∞Îùº ÏöîÏ≤≠ Íµ¨ÏÑ±
      if (typeof videoInput === 'string') {
        // GCS URI ÎòêÎäî Î°úÏª¨ ÌååÏùº Í≤ΩÎ°ú
        if (videoInput.startsWith('gs://')) {
          request = {
            inputUri: videoInput,
            features: this.features,
          };
        } else {
          // Î°úÏª¨ ÌååÏùº Ï≤òÎ¶¨
          const inputContent = readFileSync(videoInput);
          request = {
            inputContent,
            features: this.features,
          };
        }
      } else {
        // Buffer Ï≤òÎ¶¨
        request = {
          inputContent: videoInput,
          features: this.features,
        };
      }

      // ÏùåÏÑ± Ï†ÑÏÇ¨ ÏÑ§Ï†ï
      if (options.enableTranscription || options.enableSpeakerDiarization) {
        request.videoContext = {
          speechTranscriptionConfig: {
            languageCode: 'ko-KR',
            enableSpeakerDiarization: options.enableSpeakerDiarization || false,
            diarizationSpeakerCount: 2,
            enableWordTimeOffsets: true,
            enableWordConfidence: true,
          },
        };
      }

      console.log('üé¨ ÎπÑÎîîÏò§ Î∂ÑÏÑù ÏãúÏûë...');
      
      // Î∂ÑÏÑù ÏöîÏ≤≠ Ïã§Ìñâ
      const [operation] = await this.client.annotateVideo(request);
      
      console.log('‚è≥ Î∂ÑÏÑù Ï≤òÎ¶¨ Ï§ë...');
      const [result] = await operation.promise();
      
      console.log('‚úÖ ÎπÑÎîîÏò§ Î∂ÑÏÑù ÏôÑÎ£å!');
      
      return this.processResults(result);
      
    } catch (error) {
      console.error('‚ùå ÎπÑÎîîÏò§ Î∂ÑÏÑù Ï§ë Ïò§Î•ò:', error);
      throw new Error(`ÎπÑÎîîÏò§ Î∂ÑÏÑù Ïã§Ìå®: ${error instanceof Error ? error.message : 'Ïïå Ïàò ÏóÜÎäî Ïò§Î•ò'}`);
    }
  }

  /**
   * Î∂ÑÏÑù Í≤∞Í≥ºÎ•º Íµ¨Ï°∞ÌôîÎêú ÌòïÌÉúÎ°ú Î≥ÄÌôò
   */
  private processResults(result: any): VideoIntelligenceResults {
    const annotationResults = result.annotationResults?.[0];
    
    if (!annotationResults) {
      throw new Error('Î∂ÑÏÑù Í≤∞Í≥ºÍ∞Ä ÏóÜÏäµÎãàÎã§.');
    }

    // Í∞ùÏ≤¥ Ï∂îÏ†Å Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨
    const objectTracking = annotationResults.objectAnnotations?.map((obj: any) => ({
      entity: {
        entityId: obj.entity?.entityId || '',
        description: obj.entity?.description || '',
        languageCode: obj.entity?.languageCode || 'ko'
      },
      confidence: obj.confidence || 0,
      frames: obj.frames?.map((frame: any) => ({
        normalizedBoundingBox: {
          left: frame.normalizedBoundingBox?.left || 0,
          top: frame.normalizedBoundingBox?.top || 0,
          right: frame.normalizedBoundingBox?.right || 0,
          bottom: frame.normalizedBoundingBox?.bottom || 0,
        },
        timeOffset: this.parseTimeOffset(frame.timeOffset)
      })) || [],
      segment: {
        startTimeOffset: this.parseTimeOffset(obj.segment?.startTimeOffset),
        endTimeOffset: this.parseTimeOffset(obj.segment?.endTimeOffset)
      }
    })) || [];

    // ÏùåÏÑ± Ï†ÑÏÇ¨ Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨
    const speechTranscription = annotationResults.speechTranscriptions?.map((speech: any) => ({
      alternatives: speech.alternatives?.map((alt: any) => ({
        transcript: alt.transcript || '',
        confidence: alt.confidence || 0,
        words: alt.words?.map((word: any) => ({
          word: word.word || '',
          startTime: this.parseTimeOffset(word.startTime),
          endTime: this.parseTimeOffset(word.endTime),
          confidence: word.confidence || 0,
          speakerTag: word.speakerTag || 0
        })) || []
      })) || [],
      languageCode: speech.languageCode || 'ko'
    })) || [];

    // ÏñºÍµ¥ Í∞êÏßÄ Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨
    const faceDetection = annotationResults.faceAnnotations?.map((face: any) => ({
      tracks: face.tracks?.map((track: any) => ({
        segment: {
          startTimeOffset: this.parseTimeOffset(track.segment?.startTimeOffset),
          endTimeOffset: this.parseTimeOffset(track.segment?.endTimeOffset)
        },
        timestampedObjects: track.timestampedObjects?.map((obj: any) => ({
          normalizedBoundingBox: {
            left: obj.normalizedBoundingBox?.left || 0,
            top: obj.normalizedBoundingBox?.top || 0,
            right: obj.normalizedBoundingBox?.right || 0,
            bottom: obj.normalizedBoundingBox?.bottom || 0,
          },
          timeOffset: this.parseTimeOffset(obj.timeOffset),
          attributes: obj.attributes || [],
          landmarks: obj.landmarks || []
        })) || []
      })) || []
    })) || [];

    // ÏÇ¨Îûå Í∞êÏßÄ Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨
    const personDetection = annotationResults.personDetectionAnnotations?.map((person: any) => ({
      tracks: person.tracks?.map((track: any) => ({
        segment: {
          startTimeOffset: this.parseTimeOffset(track.segment?.startTimeOffset),
          endTimeOffset: this.parseTimeOffset(track.segment?.endTimeOffset)
        },
        timestampedObjects: track.timestampedObjects?.map((obj: any) => ({
          normalizedBoundingBox: {
            left: obj.normalizedBoundingBox?.left || 0,
            top: obj.normalizedBoundingBox?.top || 0,
            right: obj.normalizedBoundingBox?.right || 0,
            bottom: obj.normalizedBoundingBox?.bottom || 0,
          },
          timeOffset: this.parseTimeOffset(obj.timeOffset),
          attributes: obj.attributes || [],
          landmarks: obj.landmarks || []
        })) || []
      })) || []
    })) || [];

    // Ïû•Î©¥ Î≥ÄÌôî Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨
    const shotChanges = annotationResults.shotAnnotations?.map((shot: any) => ({
      startTimeOffset: this.parseTimeOffset(shot.startTimeOffset),
      endTimeOffset: this.parseTimeOffset(shot.endTimeOffset)
    })) || [];

    // Î™ÖÏãúÏ†Å ÏΩòÌÖêÏ∏† Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨
    const explicitContent = annotationResults.explicitAnnotation?.frames?.map((frame: any) => ({
      timeOffset: this.parseTimeOffset(frame.timeOffset),
      pornographyLikelihood: frame.pornographyLikelihood || 'VERY_UNLIKELY'
    })) || [];

    return {
      objectTracking,
      speechTranscription,
      faceDetection,
      personDetection,
      shotChanges,
      explicitContent
    };
  }

  /**
   * ÏãúÍ∞Ñ Ïò§ÌîÑÏÖã ÌååÏã±
   */
  private parseTimeOffset(timeOffset: any): number {
    if (!timeOffset) {
      return 0;
    }
    
    const seconds = parseInt(timeOffset.seconds || '0');
    const nanos = parseInt(timeOffset.nanos || '0');
    
    return seconds + nanos / 1000000000;
  }

  /**
   * ÎπÑÎîîÏò§ ÌíàÏßà Î©îÌä∏Î¶≠ Í≥ÑÏÇ∞
   */
  async calculateQualityMetrics(analysisResults: VideoIntelligenceResults): Promise<{
    videoQuality: number;
    audioQuality: number;
    overallQuality: number;
  }> {
    // ÎπÑÎîîÏò§ ÌíàÏßà ÌèâÍ∞Ä (Í∞ùÏ≤¥ Ï∂îÏ†Å Î∞è ÏñºÍµ¥ Í∞êÏßÄ Í∏∞Î∞ò)
    const videoQuality = this.assessVideoQuality(analysisResults);
    
    // Ïò§ÎîîÏò§ ÌíàÏßà ÌèâÍ∞Ä (ÏùåÏÑ± Ï†ÑÏÇ¨ Ï†ïÌôïÎèÑ Í∏∞Î∞ò)
    const audioQuality = this.assessAudioQuality(analysisResults);
    
    // Ï†ÑÏ≤¥ ÌíàÏßà Ï†êÏàò
    const overallQuality = (videoQuality + audioQuality) / 2;
    
    return {
      videoQuality: Math.round(videoQuality * 100) / 100,
      audioQuality: Math.round(audioQuality * 100) / 100,
      overallQuality: Math.round(overallQuality * 100) / 100
    };
  }

  private assessVideoQuality(results: VideoIntelligenceResults): number {
    let quality = 0.5; // Í∏∞Î≥∏ Ï†êÏàò

    // Í∞ùÏ≤¥ Ï∂îÏ†Å Îç∞Ïù¥ÌÑ∞ ÌíàÏßà ÌèâÍ∞Ä
    if (results.objectTracking?.length > 0) {
      const avgConfidence = results.objectTracking.reduce((sum, obj) => sum + obj.confidence, 0) / results.objectTracking.length;
      quality += avgConfidence * 0.3;
    }

    // ÏñºÍµ¥ Í∞êÏßÄ Îç∞Ïù¥ÌÑ∞ ÌíàÏßà ÌèâÍ∞Ä
    if (results.faceDetection?.length > 0) {
      quality += 0.2; // ÏñºÍµ¥Ïù¥ Í∞êÏßÄÎêòÎ©¥ ÌíàÏßà Ìñ•ÏÉÅ
    }

    // ÏÇ¨Îûå Í∞êÏßÄ Îç∞Ïù¥ÌÑ∞ ÌíàÏßà ÌèâÍ∞Ä
    if (results.personDetection?.length > 0) {
      quality += 0.2; // ÏÇ¨ÎûåÏù¥ Í∞êÏßÄÎêòÎ©¥ ÌíàÏßà Ìñ•ÏÉÅ
    }

    return Math.min(quality, 1.0); // ÏµúÎåÄ 1.0ÏúºÎ°ú Ï†úÌïú
  }

  private assessAudioQuality(results: VideoIntelligenceResults): number {
    let quality = 0.5; // Í∏∞Î≥∏ Ï†êÏàò

    // ÏùåÏÑ± Ï†ÑÏÇ¨ ÌíàÏßà ÌèâÍ∞Ä
    if (results.speechTranscription?.length > 0) {
      const transcriptions = results.speechTranscription;
      let totalConfidence = 0;
      let totalWords = 0;

      transcriptions.forEach(speech => {
        speech.alternatives?.forEach(alt => {
          if (alt.words) {
            alt.words.forEach(word => {
              totalConfidence += word.confidence;
              totalWords++;
            });
          }
        });
      });

      if (totalWords > 0) {
        const avgConfidence = totalConfidence / totalWords;
        quality += avgConfidence * 0.5;
      }
    }

    return Math.min(quality, 1.0); // ÏµúÎåÄ 1.0ÏúºÎ°ú Ï†úÌïú
  }

  /**
   * Î∂ÑÏÑù ÏßÑÌñâ ÏÉÅÌô© ÏΩúÎ∞±Í≥º Ìï®Íªò ÎπÑÎîîÏò§ Î∂ÑÏÑù (Ïã§ÏãúÍ∞Ñ ÏóÖÎç∞Ïù¥Ìä∏Ïö©)
   */
  async analyzeVideoWithProgress(
    videoInput: string | Buffer,
    options: VideoAnalysisOptions = {},
    progressCallback?: (progress: number, stage: string) => void
  ): Promise<VideoIntelligenceResults> {
    
    if (progressCallback) {
      progressCallback(10, 'ÎπÑÎîîÏò§ ÏóÖÎ°úÎìú Ï§ë...');
    }

    try {
      // Î∂ÑÏÑù ÏöîÏ≤≠ ÏãúÏûë
      if (progressCallback) {
        progressCallback(30, 'Î∂ÑÏÑù ÏöîÏ≤≠ Ï†ÑÏÜ° Ï§ë...');
      }

      const results = await this.analyzeVideo(videoInput, options);

      if (progressCallback) {
        progressCallback(80, 'Í≤∞Í≥º Ï≤òÎ¶¨ Ï§ë...');
      }

      // ÌíàÏßà Î©îÌä∏Î¶≠ Í≥ÑÏÇ∞
      const qualityMetrics = await this.calculateQualityMetrics(results);

      if (progressCallback) {
        progressCallback(100, 'Î∂ÑÏÑù ÏôÑÎ£å!');
      }

      return results;
    } catch (error) {
      if (progressCallback) {
        progressCallback(0, 'Î∂ÑÏÑù Ïã§Ìå®');
      }
      throw error;
    }
  }
} 